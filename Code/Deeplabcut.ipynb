{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increased-microphone",
   "metadata": {},
   "source": [
    "# DeepWorkOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-relief",
   "metadata": {},
   "source": [
    "Extracting the poses of humans without using markers is often essential for measuring behavioral effects in biomechanics. Yet, extracting detailed poses without markers in dynamically changing backgrounds has been challenging. The open source toolbox called DeepLabCut, that builds on a state-of-the-art human pose estimation algorithm, allows a user to train a deep neural network using limited training data to precisely track user-defined features that matches human labeling accuracy. In the following we will train a model that enables us to track, improve and classify the execution of a bodyweight exercise. \n",
    "The whole project 'DeepWorkOut' will be realised in 4 steps: \n",
    "\n",
    "__1. Point detection with DeepLabCut__\n",
    "\n",
    "__2. Post-processing and Data Preparation__\n",
    "\n",
    "__3. Classification of the exercise__\n",
    "\n",
    "__4. Error detection and correction__\n",
    "\n",
    "Fact sheet: \n",
    "- video lenght: 4s\n",
    "- Exercises: Plank, Plankvariation, Lunge, Squat, Crunch\n",
    "- Error detection: Plank \n",
    "- Classification: 5 exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-budget",
   "metadata": {},
   "source": [
    "# 1. Point detection with DeepLabCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greek-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Carl & Louis Enslin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-trade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut as dlc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-planning",
   "metadata": {},
   "source": [
    "## Create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thick-blocking",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "project_name = 'DeepWorkOut'\n",
    "developer = 'Carl & Louis Enslin'\n",
    "video_path = ['C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Videos']\n",
    "working_directory = 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt'\n",
    "\n",
    "#create a variable that holds the path the path to the config.yaml file\n",
    "config_path = dlc.create_new_project(project_name, developer, video_path, videotype='.avi', working_directory=working_directory, copy_videos=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-baseline",
   "metadata": {},
   "source": [
    "## Change the parameters in config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-injury",
   "metadata": {},
   "source": [
    "The Config.yaml file is the central node of DeepLabCut. This is where the body parts and many important network parameters are stored and adjusted. \n",
    "After an interative process we decided to track these bodyparts in the recordings: __ankleft, kneeleft, hipleft, shoulderleft, elbowleft, wristleft, forehead, chin, ankleright, kneeright, hipright, shoulderright, elbowright, wristright, upperback, middleback, lowerback, toesright, toesleft__\n",
    "\n",
    "Other Parameters:\n",
    "- p-cutoff: 0.8 (treshhold of the likelihood to differ a certain from an uncertain point)\n",
    "- Number of frames per video: 20\n",
    "- Training fraction: 0.95\n",
    "- General net type: Resnet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-fabric",
   "metadata": {},
   "source": [
    "## Extract frames and video selection\n",
    "\n",
    "Critical points and our ideas:\n",
    "- training should capture the full breadth of the behaviour, however it should be realisible for us\n",
    "\n",
    "-> Different clothes (log, short, dark, bright), 2 humans (at first we both), monochrome background (at first), diversity in respect to postures, 1 camera angle \n",
    "\n",
    "- large frames increases the training time\n",
    "\n",
    "-> Rreduce video resolution to 480p (results are good enough and training time is not that large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attractive-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Ausfallschritt_1.avi ?\n",
      "yes/noyes\n",
      "The directory already contains some frames. Do you want to add to it?(yes/no): yes\n",
      "Extracting frames based on uniform ...\n",
      "Uniformly extracting of frames from 0.0  seconds to 4.7  seconds.\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Ausfallschritt_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Ausfallschritt_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Ausfallschritt_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Crunch_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Crunch_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Crunch_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Crunch_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Kniebeuge_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Kniebeuge_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Kniebeuge_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Kniebeuge_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\PlankVar_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\PlankVar_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\PlankVar_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\PlankVar_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Plank_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Plank_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Plank_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\videos\\Plank_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Ausfallschritt_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Ausfallschritt_2.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Ausfallschritt_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Ausfallschritt_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\PlankVar_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Kniebeuge_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\PlankVar_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Crunch_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Plank_4.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Kniebeuge_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Kniebeuge_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Plank_1.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Crunch_3.avi ?\n",
      "yes/nono\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Videos\\Ausfallschritt_4.avi ?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a50f53e2ca2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Select the frames automatically and regularly but random from each video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdlc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'automatic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserfeedback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\frame_extraction.py\u001b[0m in \u001b[0;36mextract_frames\u001b[1;34m(config, mode, algo, crop, userfeedback, cluster_step, cluster_resizewidth, cluster_color, opencv, slider_width)\u001b[0m\n\u001b[0;32m    196\u001b[0m                     \u001b[1;34m\"?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                 )\n\u001b[1;32m--> 198\u001b[1;33m                 \u001b[0maskuser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yes/no\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                 \u001b[0maskuser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"yes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 20 frames per video (20 x 20 -> 400 frames -> 8000 bodypoints to label)\n",
    "# Select the frames automatically and regularly but random from each video\n",
    "\n",
    "dlc.extract_frames(config_path, mode='automatic', algo='uniform', userfeedback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-sperm",
   "metadata": {},
   "source": [
    "## Label frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label all the frames in the GUI (in total more than 8000!)\n",
    "dlc.label_frames(config_path)\n",
    "\n",
    "# Checking if the labels were created correctly -> good labeling is the base for a working network\n",
    "dlc.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a skeleton in the GUI to create one more metric\n",
    "# Important: Not only the \"real\" skeleton is created, but also that further connections are made for a good and general model.\n",
    "dlc.SkeletonBuilder(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-jewel",
   "metadata": {},
   "source": [
    "## Create a training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-wallpaper",
   "metadata": {},
   "source": [
    "To benchmark the performance we created different training sets to compare different parameters. In the following we will give a brief overview:\n",
    "    \n",
    "In the pose_cfg.yaml we varied different parameters. Since there is already a pre-trained model for the recognition of points on humans, we have limited our training data to the same points and adopted the weights (from the mpii-pose-single-resnet). When this worked well, we added more points (important for us to analyse) and adjusted and improved the following parameters bit by bit: optimizer, batch size, net type, augmentation, learning rate, global scale.\n",
    "The following worked best:\n",
    "- optimizer: sgd\n",
    "- batch size: 4\n",
    "- net type: renet_101\n",
    "- augmentation: imgaug\n",
    "- learning rate: multistep (0.005, 0.02)\n",
    "- global scale: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pregnant-vanilla",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([352, 435, 453, 218, 614, 466, 449, 573,  26, 310, 576, 764, 457,\n",
       "           96, 257, 636, 712,  63,  48, 280, 754, 342, 491, 510,  41, 157,\n",
       "          382, 759, 456, 425, 682, 481, 167, 627, 723, 766, 623, 391, 788,\n",
       "          665,  65, 375, 607, 263, 397, 387, 744, 725, 402, 635, 249,  99,\n",
       "          742, 749, 757, 755, 344, 685, 780, 520, 653, 597, 734, 698, 680,\n",
       "          618, 497, 480, 180,   1, 199, 398, 350, 314, 278, 389, 330, 729,\n",
       "          782, 476, 545, 414, 643, 794, 226, 547, 143, 206, 390, 441, 502,\n",
       "          388, 462, 238, 705, 147, 606, 266,  62, 639, 153, 253, 784, 212,\n",
       "           47, 196, 241, 608, 562,  13, 353, 327, 140, 108,  61,  87, 185,\n",
       "          166, 341, 767, 695, 574, 455, 380, 191, 415,  38, 182,  31, 404,\n",
       "          633, 343, 626, 664, 420, 242, 434, 498, 509, 513, 222, 198, 684,\n",
       "           67, 232, 281, 368, 644, 617, 671, 689,  78, 169, 701, 797, 500,\n",
       "          558, 800, 245, 359, 366, 485,  75, 557, 233, 556, 117,   5, 732,\n",
       "          736,   6, 470, 789, 709, 294, 287, 270, 539, 203, 254,  43, 162,\n",
       "          251, 580, 511,  22,  16,  10, 598, 624,  19, 268, 303, 518, 439,\n",
       "           92, 787,  58, 739, 679, 137, 332, 594, 423, 567, 681, 798, 360,\n",
       "          691, 637, 761, 447, 589, 590, 601,  56, 537, 230, 115, 650, 670,\n",
       "          542, 777, 406, 522,  74, 611,  18, 781, 706, 252, 378, 277,  37,\n",
       "          738, 107,  55, 571, 105, 148, 550, 581, 468, 632, 487,  68, 467,\n",
       "          703, 265,  57, 647,  12, 312, 119,   8, 551, 262, 622, 189, 210,\n",
       "           17, 459,  51, 577, 186, 593, 428, 548, 595, 358, 325,  71, 652,\n",
       "          112, 488, 675, 646, 377, 596, 586, 599, 474, 676, 170, 417,   2,\n",
       "          696, 328, 400,  94, 324,  84,  85, 432, 716, 478, 193, 114, 333,\n",
       "          371, 320, 475, 116, 134, 258, 533, 208, 184, 536, 778, 715, 172,\n",
       "          286, 728, 248, 214, 578, 641,  34, 424, 187, 361, 216, 283, 673,\n",
       "          124,  86,  73, 746, 587, 334, 106,   9, 785, 109,  76, 217, 308,\n",
       "          490, 386, 741, 657,  27, 619, 464, 454, 529, 131,  28, 369, 385,\n",
       "          354,  70, 433, 201, 702, 267, 448, 628, 282, 659, 697, 269, 612,\n",
       "          688, 656, 141,  72, 528, 412, 560, 164, 553, 451, 724, 669, 419,\n",
       "          309,  32, 803,  89, 731, 195, 615, 149, 347, 139, 804, 585, 492,\n",
       "          215, 229, 519, 307, 584, 582, 146, 240, 373, 200, 316, 505, 152,\n",
       "          192, 329, 244, 165, 372, 326, 340,  88,   4, 786, 735, 489,  30,\n",
       "          275, 383, 438, 530, 313, 631, 197,  52, 292, 144, 154, 704,  82,\n",
       "          235, 444, 337, 722, 634, 572, 296, 802, 753, 469, 311, 591, 526,\n",
       "           40, 259, 158, 300, 285, 207,  97, 272, 638, 204, 421, 135, 779,\n",
       "          129, 362, 159, 540, 613, 569,  49,  59, 792, 663, 363, 460, 379,\n",
       "          482, 260, 796, 239, 508, 211, 156, 426, 535, 161, 515, 223,  36,\n",
       "          521, 473, 507, 104, 297, 145, 384, 370, 707, 395, 335, 364, 527,\n",
       "          430, 686, 523,  42, 758, 289, 401, 790, 163, 776, 250, 209, 763,\n",
       "          471, 403, 351, 394,  98, 604, 130, 700, 504, 315, 179, 514, 771,\n",
       "          126, 177, 228, 770, 642, 678, 603, 568, 225, 393, 111, 399, 541,\n",
       "          411, 693,  54, 750, 563, 554, 247, 531, 176, 773, 602,  77, 621,\n",
       "          711, 279, 306, 100, 321,  50, 110, 484, 768, 349, 660, 407,  35,\n",
       "           20, 494, 616, 532, 674, 718, 127, 264, 549, 600,  45, 565,  66,\n",
       "          405, 274, 290, 178, 431, 666,  29, 714, 483, 610, 588, 138,  44,\n",
       "          499, 243, 446, 719, 246,   0, 103,  90, 694, 747, 555, 396, 570,\n",
       "          743, 227, 472, 151, 173, 769, 318, 727, 255, 445, 301, 625, 730,\n",
       "          745, 708, 128, 345, 452, 174, 630, 367, 772, 123, 136, 102, 221,\n",
       "          338, 261,  93, 552, 224, 493, 356, 740, 525, 374,  24,  81, 752,\n",
       "          256, 427, 713, 331, 339, 495, 231,  91, 213, 381,  64,  23, 805,\n",
       "          188, 710, 667, 645, 486, 336, 276, 512, 416, 609, 677, 516, 640,\n",
       "          436, 288, 672, 721, 524,  53, 748, 150, 155, 605, 323, 202, 629,\n",
       "           69, 737, 546, 692, 561, 437, 717, 775, 559,  46, 194, 295,   3,\n",
       "          304, 564, 503, 654, 751, 190, 317, 465, 236, 655, 620, 799, 517,\n",
       "           33, 760,  14,  60, 118, 220, 357, 284, 121, 583, 175,  83, 783,\n",
       "          271, 132, 458, 422, 658, 305, 291, 160, 410, 793, 506, 544, 120,\n",
       "          662, 442, 795, 687, 443, 413, 496,  21, 183, 122,  15, 355, 418,\n",
       "          477, 450, 699, 726, 575, 101, 538, 365, 806, 661, 302,  25, 791,\n",
       "          756, 683, 346, 579, 273, 461, 168, 774, 690,  11, 376, 720]),\n",
       "   array([392, 762,  39, 429, 543, 299, 765, 534, 298, 479, 408, 319,  79,\n",
       "          668, 592, 463,   7, 648, 237, 801, 125, 142, 219, 322,  80, 440,\n",
       "           95, 348, 649, 409, 501, 733, 171, 651, 293, 234, 181, 205, 566,\n",
       "          113, 133])))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_shuffle: type of our training configuration \n",
    "# Create different training dataset to compare after training\n",
    "dlc.create_training_model_comparison(config_path, num_shuffles=2, net_types=['resnet_101', 'resnet_152'], augmenter_types=['imgaug', 'default'])\n",
    "\n",
    "dlc.create_training_dataset(config_path, net_type='resnet_101', augmenter_type='imgaug')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-battery",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18]],\n",
      " 'all_joints_names': ['ankleleft',\n",
      "                      'kneeleft',\n",
      "                      'hipleft',\n",
      "                      'shoulderleft',\n",
      "                      'elbowleft',\n",
      "                      'wristleft',\n",
      "                      'forehead',\n",
      "                      'chin',\n",
      "                      'ankleright',\n",
      "                      'kneeright',\n",
      "                      'hipright',\n",
      "                      'shoulderright',\n",
      "                      'elbowright',\n",
      "                      'wristright',\n",
      "                      'upperback',\n",
      "                      'middleback',\n",
      "                      'lowerback',\n",
      "                      'toesright',\n",
      "                      'toesleft'],\n",
      " 'batch_size': 4,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.25,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DeepWorkOutJan31\\\\DeepWorkOut_Carl '\n",
      "            '& Louis Enslin95shuffle4.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 1.0,\n",
      " 'init_weights': 'C:\\\\Users\\\\ujtjf\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mpii-single-resnet-101',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DeepWorkOutJan31\\\\Documentation_data-DeepWorkOut_95shuffle4.pickle',\n",
      " 'min_input_size': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.02, 10000],\n",
      "                [0.005, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_101',\n",
      " 'num_joints': 19,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt\\\\DeepWorkOut-Carl '\n",
      "                 '& Louis Enslin-2021-01-31',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt\\\\DeepWorkOut-Carl '\n",
      "                    '& Louis '\n",
      "                    'Enslin-2021-01-31\\\\dlc-models\\\\iteration-0\\\\DeepWorkOutJan31-trainset95shuffle4\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 4\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_101\n",
      "Max_iters overwritten as 100000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt\\\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\\\dlc-models\\\\iteration-0\\\\DeepWorkOutJan31-trainset95shuffle4\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 1.0, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 4, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18]], 'all_joints_names': ['ankleleft', 'kneeleft', 'hipleft', 'shoulderleft', 'elbowleft', 'wristleft', 'forehead', 'chin', 'ankleright', 'kneeright', 'hipright', 'shoulderright', 'elbowright', 'wristright', 'upperback', 'middleback', 'lowerback', 'toesright', 'toesleft'], 'cropratio': 0.25, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DeepWorkOutJan31\\\\DeepWorkOut_Carl & Louis Enslin95shuffle4.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\ujtjf\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mpii-single-resnet-101', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DeepWorkOutJan31\\\\Documentation_data-DeepWorkOut_95shuffle4.pickle', 'min_input_size': 100, 'multi_step': [[0.02, 10000], [0.005, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_101', 'num_joints': 19, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt\\\\DeepWorkOut-Carl & Louis Enslin-2021-01-31', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0249 lr: 0.02\n",
      "iteration: 2000 loss: 0.0118 lr: 0.02\n",
      "iteration: 3000 loss: 0.0097 lr: 0.02\n",
      "iteration: 4000 loss: 0.0087 lr: 0.02\n",
      "iteration: 5000 loss: 0.0080 lr: 0.02\n",
      "iteration: 6000 loss: 0.0076 lr: 0.02\n",
      "iteration: 7000 loss: 0.0071 lr: 0.02\n",
      "iteration: 8000 loss: 0.0066 lr: 0.02\n",
      "iteration: 9000 loss: 0.0064 lr: 0.02\n",
      "iteration: 10000 loss: 0.0062 lr: 0.02\n",
      "iteration: 11000 loss: 0.0056 lr: 0.005\n",
      "iteration: 12000 loss: 0.0055 lr: 0.005\n",
      "iteration: 13000 loss: 0.0054 lr: 0.005\n",
      "iteration: 14000 loss: 0.0054 lr: 0.005\n",
      "iteration: 15000 loss: 0.0053 lr: 0.005\n",
      "iteration: 16000 loss: 0.0053 lr: 0.005\n",
      "iteration: 17000 loss: 0.0052 lr: 0.005\n",
      "iteration: 18000 loss: 0.0053 lr: 0.005\n",
      "iteration: 19000 loss: 0.0052 lr: 0.005\n",
      "iteration: 20000 loss: 0.0051 lr: 0.005\n",
      "iteration: 21000 loss: 0.0050 lr: 0.005\n",
      "iteration: 22000 loss: 0.0051 lr: 0.005\n",
      "iteration: 23000 loss: 0.0050 lr: 0.005\n",
      "iteration: 24000 loss: 0.0050 lr: 0.005\n",
      "iteration: 25000 loss: 0.0049 lr: 0.005\n",
      "iteration: 26000 loss: 0.0049 lr: 0.005\n",
      "iteration: 27000 loss: 0.0049 lr: 0.005\n",
      "iteration: 28000 loss: 0.0049 lr: 0.005\n",
      "iteration: 29000 loss: 0.0048 lr: 0.005\n",
      "iteration: 30000 loss: 0.0048 lr: 0.005\n",
      "iteration: 31000 loss: 0.0047 lr: 0.005\n",
      "iteration: 32000 loss: 0.0048 lr: 0.005\n",
      "iteration: 33000 loss: 0.0047 lr: 0.005\n",
      "iteration: 34000 loss: 0.0047 lr: 0.005\n",
      "iteration: 35000 loss: 0.0047 lr: 0.005\n",
      "iteration: 36000 loss: 0.0046 lr: 0.005\n",
      "iteration: 37000 loss: 0.0047 lr: 0.005\n",
      "iteration: 38000 loss: 0.0047 lr: 0.005\n",
      "iteration: 39000 loss: 0.0047 lr: 0.005\n",
      "iteration: 40000 loss: 0.0046 lr: 0.005\n",
      "iteration: 41000 loss: 0.0046 lr: 0.005\n",
      "iteration: 42000 loss: 0.0045 lr: 0.005\n",
      "iteration: 43000 loss: 0.0045 lr: 0.005\n",
      "iteration: 44000 loss: 0.0045 lr: 0.005\n",
      "iteration: 45000 loss: 0.0044 lr: 0.005\n",
      "iteration: 46000 loss: 0.0044 lr: 0.005\n",
      "iteration: 47000 loss: 0.0044 lr: 0.005\n",
      "iteration: 48000 loss: 0.0043 lr: 0.005\n",
      "iteration: 49000 loss: 0.0044 lr: 0.005\n",
      "iteration: 50000 loss: 0.0044 lr: 0.005\n",
      "iteration: 51000 loss: 0.0043 lr: 0.005\n",
      "iteration: 52000 loss: 0.0043 lr: 0.005\n",
      "iteration: 53000 loss: 0.0044 lr: 0.005\n",
      "iteration: 54000 loss: 0.0042 lr: 0.005\n",
      "iteration: 55000 loss: 0.0043 lr: 0.005\n",
      "iteration: 56000 loss: 0.0043 lr: 0.005\n",
      "iteration: 57000 loss: 0.0043 lr: 0.005\n",
      "iteration: 58000 loss: 0.0042 lr: 0.005\n",
      "iteration: 59000 loss: 0.0042 lr: 0.005\n",
      "iteration: 60000 loss: 0.0042 lr: 0.005\n",
      "iteration: 61000 loss: 0.0042 lr: 0.005\n",
      "iteration: 62000 loss: 0.0042 lr: 0.005\n",
      "iteration: 63000 loss: 0.0041 lr: 0.005\n",
      "iteration: 64000 loss: 0.0041 lr: 0.005\n",
      "iteration: 65000 loss: 0.0041 lr: 0.005\n",
      "iteration: 66000 loss: 0.0041 lr: 0.005\n",
      "iteration: 67000 loss: 0.0041 lr: 0.005\n",
      "iteration: 68000 loss: 0.0041 lr: 0.005\n",
      "iteration: 69000 loss: 0.0040 lr: 0.005\n",
      "iteration: 70000 loss: 0.0040 lr: 0.005\n",
      "iteration: 71000 loss: 0.0041 lr: 0.005\n",
      "iteration: 72000 loss: 0.0040 lr: 0.005\n",
      "iteration: 73000 loss: 0.0040 lr: 0.005\n",
      "iteration: 74000 loss: 0.0040 lr: 0.005\n",
      "iteration: 75000 loss: 0.0040 lr: 0.005\n",
      "iteration: 76000 loss: 0.0039 lr: 0.005\n",
      "iteration: 77000 loss: 0.0040 lr: 0.005\n",
      "iteration: 78000 loss: 0.0040 lr: 0.005\n",
      "iteration: 79000 loss: 0.0039 lr: 0.005\n",
      "iteration: 80000 loss: 0.0039 lr: 0.005\n",
      "iteration: 81000 loss: 0.0040 lr: 0.005\n",
      "iteration: 82000 loss: 0.0039 lr: 0.005\n",
      "iteration: 83000 loss: 0.0039 lr: 0.005\n",
      "iteration: 84000 loss: 0.0039 lr: 0.005\n",
      "iteration: 85000 loss: 0.0039 lr: 0.005\n",
      "iteration: 86000 loss: 0.0039 lr: 0.005\n",
      "iteration: 87000 loss: 0.0039 lr: 0.005\n",
      "iteration: 88000 loss: 0.0038 lr: 0.005\n",
      "iteration: 89000 loss: 0.0039 lr: 0.005\n",
      "iteration: 90000 loss: 0.0038 lr: 0.005\n",
      "iteration: 91000 loss: 0.0038 lr: 0.005\n",
      "iteration: 92000 loss: 0.0038 lr: 0.005\n",
      "iteration: 93000 loss: 0.0038 lr: 0.005\n",
      "iteration: 94000 loss: 0.0038 lr: 0.005\n",
      "iteration: 95000 loss: 0.0038 lr: 0.005\n",
      "iteration: 96000 loss: 0.0038 lr: 0.005\n",
      "iteration: 97000 loss: 0.0038 lr: 0.005\n",
      "iteration: 98000 loss: 0.0037 lr: 0.005\n",
      "iteration: 99000 loss: 0.0038 lr: 0.005\n",
      "iteration: 100000 loss: 0.0037 lr: 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 91, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2878, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-e4fd8f19987d>\", line 1, in <module>\n",
      "    dlc.train_network(config_path, maxiters=100000, shuffle=4)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 189, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 172, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 77, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\ujtjf\\Anaconda3\\envs\\Clone DLC\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:77) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dlc.train_network(config_path, maxiters=100000, shuffle=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-lexington",
   "metadata": {},
   "source": [
    "## Start evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-issue",
   "metadata": {},
   "source": [
    "After training, we evaluated our model using the train/test loss and the pixel error. We achieved a loss of 0.00308 and a test pixel error of 2.37. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imported-grill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18]],\n",
      " 'all_joints_names': ['ankleleft',\n",
      "                      'kneeleft',\n",
      "                      'hipleft',\n",
      "                      'shoulderleft',\n",
      "                      'elbowleft',\n",
      "                      'wristleft',\n",
      "                      'forehead',\n",
      "                      'chin',\n",
      "                      'ankleright',\n",
      "                      'kneeright',\n",
      "                      'hipright',\n",
      "                      'shoulderright',\n",
      "                      'elbowright',\n",
      "                      'wristright',\n",
      "                      'upperback',\n",
      "                      'middleback',\n",
      "                      'lowerback',\n",
      "                      'toesright',\n",
      "                      'toesleft'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_DeepWorkOutJan31\\\\DeepWorkOut_Carl '\n",
      "            '& Louis Enslin95shuffle6.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 1.0,\n",
      " 'init_weights': 'C:\\\\Users\\\\ujtjf\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\mpii-single-resnet-101',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_101',\n",
      " 'num_joints': 19,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Deeplabcut_projekt\\\\DeepWorkOut-Carl '\n",
      "                    '& Louis '\n",
      "                    'Enslin-2021-01-31\\\\dlc-models\\\\iteration-0\\\\DeepWorkOutJan31-trainset95shuffle6\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "  0%|          | 0/399 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31/evaluation-results/  already exists!\n",
      "C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\evaluation-results\\iteration-0\\DeepWorkOutJan31-trainset95shuffle6  already exists!\n",
      "Running  DLC_resnet101_DeepWorkOutJan31shuffle6_200000  with # of trainingiterations: 200000\n",
      "This net has already been evaluated!\n",
      "Plotting...(attention scale might be inconsistent in comparison to when data was analyzed; i.e. if you used rescale)\n",
      "C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\evaluation-results\\iteration-0\\DeepWorkOutJan31-trainset95shuffle6\\LabeledImages_DLC_resnet101_DeepWorkOutJan31shuffle6_200000_snapshot-200000  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [01:21<00:00,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "dlc.evaluate_network(config_path, plotting=True, Shuffles=[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "widespread-guard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss of our different modells\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "filename1 = 'Deeplabcut_projekt/DeepWorkOut-Carl & Louis Enslin-2021-01-31/dlc-models/iteration-0/DeepWorkOutJan31-trainset95shuffle3/train/learning_stats.csv'\n",
    "filename2 = 'Deeplabcut_projekt/DeepWorkOut-Carl & Louis Enslin-2021-01-31/dlc-models/iteration-0/DeepWorkOutJan31-trainset95shuffle4/train/learning_stats.csv'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "colnames = ['Iterations', 'loss', 'lr']\n",
    "data1 = pd.read_csv(filename1, names=colnames)\n",
    "data2 = pd.read_csv(filename2, names=colnames)\n",
    "\n",
    "ax.plot(data1['Iterations'], data1['loss'], label='0.005 0.02', color='red')\n",
    "ax.plot(data2['Iterations'], data2['loss'], label='0.02 0.005', color='blue')\n",
    "\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-correlation",
   "metadata": {},
   "source": [
    "## Start analyzing videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-dublin",
   "metadata": {},
   "source": [
    "Now that we have a model, we can analyse different videos and then process them. After the analysis of each video we get a file with all the positions of the bodypositions (x, y) and the probability of correctness. These data are further processed in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "backed-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "videofile_path = ['C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Testvideos']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quick-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-100000 for model C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Deeplabcut_projekt\\DeepWorkOut-Carl & Louis Enslin-2021-01-31\\dlc-models\\iteration-0\\DeepWorkOutJan31-trainset95shuffle3\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/596 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Video_1.mov\n",
      "C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos  already exists!\n",
      "Loading  C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos\\Video_1.mov\n",
      "Duration of video [s]:  20.46 , recorded with  29.13 fps!\n",
      "Overall # of frames:  596  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [00:10, 55.09it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  596\n",
      "Saving results in C:\\Users\\ujtjf\\Desktop\\LAMA_Projekt\\Testvideos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet101_DeepWorkOutJan31shuffle3_100000'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc.analyze_videos(config_path, videofile_path, videotype='.mov', shuffle=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-object",
   "metadata": {},
   "source": [
    "## Extract outlier frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-signature",
   "metadata": {},
   "source": [
    "Since the points are not yet perfect, we have now searched the whole video for outliers and selected the corresponding frames. We can correct these frames and thus expand our training set with decisive and critical points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boring-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_adress = ['C:\\\\Users\\\\ujtjf\\\\Desktop\\\\LAMA_Projekt\\\\Testvideos']\n",
    "dlc.extract_outlier_frames(config_path, video_adress, shuffle=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "young-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Refine labels\n",
    "dlc.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "statutory-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "dlc.merge_datasets(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-briefing",
   "metadata": {},
   "source": [
    "## Create labeled video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "robust-amplifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n"
     ]
    }
   ],
   "source": [
    "# labeled video is created\n",
    "dlc.create_labeled_video(config_path, video_adress, videotype='.mov', shuffle=3, draw_skeleton=True, trailpoints=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-prompt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Clone DLC] *",
   "language": "python",
   "name": "conda-env-Clone_DLC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
